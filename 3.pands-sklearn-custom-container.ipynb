{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28d5a597-2658-4c2e-bdda-944c2dab87ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-aiplatform[prediction]@git+https://github.com/googleapis/python-aiplatform.git@custom-prediction-routine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201e92f9-980b-43e9-8c76-b2aa02260e96",
   "metadata": {},
   "source": [
    "# Sklearn with Pandas - Custom Prediction Routine to get `.predict_proba()`\n",
    "\n",
    "This is similar to [the other notebook](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_cpr.ipynb) except we will be using pandas and bigquery\n",
    "\n",
    "Topics covered\n",
    "* Training sklearn locally, deploying to endpoint\n",
    "* Saving data as CSV and doing batch predict from GCS\n",
    "* Loading data to BQ, using BQ magics\n",
    "* Running a batch prediction from BQ to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9cbe8a06-ed15-40ac-bc2f-d387bb406301",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'wortz-project' #SET THIS TO YOUR PROJECT ID\n",
    "BUCKET = \"gs://xxx-model-artifacts\" #BE SURE TO gsutil mb -l <REGION> <LOG_BUCKET> to create the bucket on GCP\n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb15f1f6-9bc5-4e82-9c4f-3f9c33882868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic data\n",
    "import pandas as pd\n",
    "import numpy as np #for the random integer example\n",
    "\n",
    "# set seed\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "x = np.random.randint(0.0,100.0,size=(10,3))\n",
    "y = np.random.binomial(1, .25, size=(10,1))\n",
    "df = pd.DataFrame(np.append(x, y, axis=1),\n",
    "              index=range(10,20),\n",
    "              columns=['col1','col2','col3','label'],\n",
    "              dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13825936-816a-4b3f-a624-7c7684fc7c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>53.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>92.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>73.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>76.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    col1  col2  col3  label\n",
       "10  47.0  83.0  38.0    0.0\n",
       "11  53.0  76.0  24.0    1.0\n",
       "12  15.0  49.0  23.0    0.0\n",
       "13  26.0  30.0  43.0    0.0\n",
       "14  30.0  26.0  58.0    1.0\n",
       "15  92.0  69.0  80.0    0.0\n",
       "16  73.0  47.0  50.0    0.0\n",
       "17  76.0  37.0  34.0    1.0\n",
       "18  38.0  67.0  11.0    0.0\n",
       "19   0.0  75.0  80.0    1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0849f09-5f48-4e73-96db-c2fa53c06ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=6, max_features=3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Set the model parameters. \n",
    "n_estimators = 100\n",
    "max_depth = 6\n",
    "max_features = 3\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = n_estimators, max_depth = max_depth, max_features = max_features)\n",
    "rf.fit(df[['col1', 'col2', 'col3']], df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9d32fb67-b6f8-40fc-b335-95c41c2c3133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "artifact_filename = 'model.joblib' #has to be joblib to work with CPR\n",
    "\n",
    "# Save model artifact to local filesystem (doesn't persist)\n",
    "\n",
    "joblib.dump(rf, artifact_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07022a43-5b9b-45bc-84af-f43173e627a4",
   "metadata": {},
   "source": [
    "#### Upload the model pipeline to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41e83b92-13d2-4881-b27f-091e96af4262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 78.7 KiB/ 78.7 KiB]                                                \n",
      "Operation completed over 1 objects/78.7 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp $artifact_filename $BUCKET/model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c749d4-18ca-46a0-91f9-432dbf1220e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create a generic sklearn container that returns `predict_proba`\n",
    "\n",
    "https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_cpr.ipynb\n",
    "\n",
    "**highly recommend reviewing this notebook first as it breaks down the custom predictor interface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bf429ed-e23c-47ac-93da-8a70c4e3e92a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘src’: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4af962a7-3196-4b9a-9c36-3f35fd525b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/requirements.txt\n",
    "fastapi\n",
    "uvicorn\n",
    "joblib~=1.0\n",
    "numpy~=1.20\n",
    "scikit-learn~=1.0\n",
    "google-cloud-storage>=1.26.0,<2.0.0dev\n",
    "google-cloud-aiplatform[prediction] @ git+https://github.com/googleapis/python-aiplatform.git@custom-prediction-routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d808c149-acef-4d7f-873a-62f372f3393e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/predictor.py\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud.aiplatform.prediction.sklearn.predictor import SklearnPredictor\n",
    "import json\n",
    "\n",
    "class CprPredictor(SklearnPredictor):\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load(self, gcs_artifacts_uri: str):\n",
    "        \"\"\"Loads the preprocessor artifacts.\"\"\"\n",
    "        gcs_client = storage.Client()\n",
    "        with open(\"model.joblib\", 'wb') as gcs_model:\n",
    "            gcs_client.download_blob_to_file(\n",
    "                gcs_artifacts_uri + \"/model.joblib\", gcs_model\n",
    "            )\n",
    "\n",
    "        with open(\"model.joblib\", \"rb\") as f:\n",
    "            self._model = joblib.load(\"model.joblib\")\n",
    "\n",
    "    \n",
    "    def predict(self, instances):\n",
    "        outputs = self._model.predict_proba(instances) \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a17737-58ad-4819-9b2d-72de6fd6e827",
   "metadata": {},
   "source": [
    "### Build and push container to Artifact Registry\n",
    "#### Build your container\n",
    "To build a custom container, we also need to write an entrypoint of the image that starts the model server. However, with the Custom Prediction Routine feature, you don't need to write the entrypoint anymore. Vertex AI SDK will populate the entrypoint with the custom predictor you provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05bf27d9-03c8-46e7-9dd3-45b6586f1316",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.utils.prediction_utils:\"src/entrypoint.py\" already exists, skip generating \"entrypoint.py\" in \"src\".\n",
      "INFO:google.cloud.aiplatform.docker_utils.build:Running command: docker build -t us-central1-docker.pkg.dev/wortz-project/custom-preprocess-container-prediction/sklearn-cpr-preprocess-server --rm -f- src\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Sending build context to Docker daemon  8.751kB\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 1/11 : FROM python:3.7\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> 7c891de3e220\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 2/11 : ENV PYTHONDONTWRITEBYTECODE=1\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> df138691af1e\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 3/11 : EXPOSE 8080\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> 6c58bab45e3a\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 4/11 : ENTRYPOINT [\"python\", \"src/entrypoint.py\"]\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> d780672f9538\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 5/11 : RUN mkdir -m 777 -p /usr/app /home\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> 34931585ead2\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 6/11 : WORKDIR /usr/app\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> d3b29fa01e1e\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 7/11 : ENV HOME=/home\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> f43558dcfba3\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 8/11 : RUN pip install --no-cache-dir --force-reinstall 'google-cloud-aiplatform[prediction] @ git+https://github.com/googleapis/python-aiplatform.git@custom-prediction-routine'\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> c68df52d92f5\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 9/11 : COPY [\"requirements.txt\", \"./requirements.txt\"]\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> f9a9e0dfb82d\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 10/11 : RUN pip install --no-cache-dir --force-reinstall -r ./requirements.txt\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> Using cache\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> 084b3a0fa36f\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Step 11/11 : COPY [\".\", \"src\"]\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util: ---> 2cb3cf69b10f\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Successfully built 2cb3cf69b10f\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Successfully tagged us-central1-docker.pkg.dev/wortz-project/custom-preprocess-container-prediction/sklearn-cpr-preprocess-server:latest\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "REGION = 'us-central1'\n",
    "\n",
    "from google.cloud.aiplatform.prediction import LocalModel\n",
    "from src.predictor import CprPredictor\n",
    "\n",
    "REPOSITORY = \"custom-preprocess-container-prediction\"  # @param {type:\"string\"}\n",
    "SERVER_IMAGE = \"sklearn-cpr-preprocess-server\"  # @param {type:\"string\"}\n",
    "\n",
    "local_model = LocalModel.create_cpr_model(\n",
    "    \"src\",\n",
    "    f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{SERVER_IMAGE}\",\n",
    "    predictor=CprPredictor,\n",
    "    requirements_path=\"src/requirements.txt\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80330616-933a-4ec9-9322-2dd5815c4947",
   "metadata": {},
   "source": [
    "### Test it out with a locally deployed endpoint\n",
    "Need to generate credentials to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a01981a9-6972-4eb9-b7ba-18689a31b90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_uri: \"us-central1-docker.pkg.dev/wortz-project/custom-preprocess-container-prediction/sklearn-cpr-preprocess-server\"\n",
       "predict_route: \"/predict\"\n",
       "health_route: \"/health\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model.get_serving_container_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1499c3a-71d5-4b1c-8ab5-09cb11a212be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! gcloud services enable iam.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa05b7-4303-4655-9cc0-069be8bcf969",
   "metadata": {},
   "source": [
    "#### Only run once to generate creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "741aa916-d6e6-47eb-8463-867cba4eca94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! gcloud iam service-accounts keys create credentials.json --iam-account=633325234048-compute@developer.gserviceaccount.com\n",
    "CREDENTIALS_FILE = \"credentials.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f057e698-b11f-4aa3-9aa5-4e23021dcc1b",
   "metadata": {},
   "source": [
    "## Create example instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "65d19e00-fd9a-4166-a6ec-324a8d37208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"instances.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2deece3e-c7f0-4513-be68-114746a5ebbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting instances.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $INPUT_FILE\n",
    "{\n",
    "    \"instances\": [\n",
    "        [61.7, 11.1, 41.7],\n",
    "        [41.6, 31.1, 11.5]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b7bcac6-86de-4afe-a70f-ff7eadfe2865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.prediction.local_endpoint:Got the project id from the global config: wortz-project.\n"
     ]
    }
   ],
   "source": [
    "with local_model.deploy_to_local_endpoint(\n",
    "    artifact_uri=f\"{BUCKET}/model\",\n",
    "    credential_path=CREDENTIALS_FILE,  # Update this to the path to your credentials.\n",
    ") as local_endpoint:\n",
    "    predict_response = local_endpoint.predict(\n",
    "        request_file=INPUT_FILE,\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "\n",
    "    health_check_response = local_endpoint.run_health_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97275bb5-4268-4222-b059-c195c6144d27",
   "metadata": {},
   "source": [
    "## Local results should show a n x 2 shaped return for binomial classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb292702-f06f-454a-a90f-e259f7578f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"predictions\": [[0.37, 0.63], [0.67, 0.33]]}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963400a8-e35a-49eb-854f-46a5421901a9",
   "metadata": {},
   "source": [
    "### Create a repository to house your artifacts / images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eea578e6-7b7c-4317-927a-d80741553859",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.beta.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    }
   ],
   "source": [
    "! gcloud beta artifacts repositories create {REPOSITORY} \\\n",
    "    --repository-format=docker \\\n",
    "    --location=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51a36035-b4ad-4ffa-97cd-444ebbbaf03e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "! gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a979a4-48a8-4453-90a3-3629957bd878",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload the model to Vertex using new Prediction Route Serving Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59eb3650-759a-40a1-bd2f-704daad82410",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.docker_utils.local_util:Using default tag: latest\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:The push refers to repository [us-central1-docker.pkg.dev/wortz-project/custom-preprocess-container-prediction/sklearn-cpr-preprocess-server]\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:f85dc2438b81: Preparing\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:ff0aeb915ea5: Preparing\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:958be198471c: Preparing\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:7a49e899b9ac: Preparing\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:1ab435391482: Preparing\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:ea02e4889d36: Preparing\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:c4418e789e70: Preparing\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:7c12a541abbf: Preparing\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:6d95196cbe50: Preparing\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:5bdcc8e2060c: Preparing\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:08fa02ce37eb: Preparing\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:a037458de4e0: Preparing\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:bafdbe68e4ae: Preparing\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:a13c519c6361: Preparing\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:08fa02ce37eb: Waiting\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:ea02e4889d36: Waiting\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:c4418e789e70: Waiting\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:a037458de4e0: Waiting\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:bafdbe68e4ae: Waiting\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:a13c519c6361: Waiting\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:7c12a541abbf: Waiting\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:6d95196cbe50: Waiting\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:5bdcc8e2060c: Waiting\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:ff0aeb915ea5: Layer already exists\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:1ab435391482: Layer already exists\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:7a49e899b9ac: Layer already exists\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:958be198471c: Layer already exists\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:ea02e4889d36: Layer already exists\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:c4418e789e70: Layer already exists\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:7c12a541abbf: Layer already exists\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:6d95196cbe50: Layer already exists\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:5bdcc8e2060c: Layer already exists\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:08fa02ce37eb: Layer already exists\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:bafdbe68e4ae: Layer already exists\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:a037458de4e0: Layer already exists\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:a13c519c6361: Layer already exists\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:f85dc2438b81: Pushed\n",
      "\n",
      "INFO:google.cloud.aiplatform.docker_utils.local_util:latest: digest: sha256:e4a33feaac34312bbc6c2b5ce63a72b320284847ab51c097d9f3f1a3a3f82418 size: 3266\n",
      "\n"
     ]
    }
   ],
   "source": [
    "local_model.push_image() #push to container registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "80d8e71d-9702-4c7d-bd15-925278f759d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Model\n",
      "INFO:google.cloud.aiplatform.models:Create Model backing LRO: projects/633325234048/locations/us-central1/models/9111965120682000384/operations/7544196298367303680\n",
      "INFO:google.cloud.aiplatform.models:Model created. Resource name: projects/633325234048/locations/us-central1/models/9111965120682000384\n",
      "INFO:google.cloud.aiplatform.models:To use this Model in another session:\n",
      "INFO:google.cloud.aiplatform.models:model = aiplatform.Model('projects/633325234048/locations/us-central1/models/9111965120682000384')\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "model = local_model.upload(\n",
    "        display_name='pandas test CLASSIFICATION',\n",
    "        artifact_uri=\"gs://ulta-model-artifacts/model\",\n",
    "        description='pandas test for deploying models to vertex CLASSIFICATION',\n",
    "        sync=True, #this will not bind up your notebook instance with the creation operation\n",
    "    ) #note this will automatcially designate the latest sklearn serving container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7e030-a234-40ad-8c8d-bc0ece95d93f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Batch predictions with GCS / CSV\n",
    "### Now we will create a different dataframe to make predictions on for batch predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f8328221-1c7c-4c65-bf71-59b59b75a7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.47, 0.53],\n",
       "       [0.29, 0.71],\n",
       "       [0.63, 0.37],\n",
       "       [0.68, 0.32],\n",
       "       [0.67, 0.33],\n",
       "       [0.35, 0.65],\n",
       "       [0.44, 0.56],\n",
       "       [0.36, 0.64],\n",
       "       [0.89, 0.11],\n",
       "       [0.45, 0.55]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(np.random.randint(0.0,100.0,size=(10,3)), # we will do batch predictions based on this\n",
    "              index=range(10,20),\n",
    "              columns=['col1','col2','col3'],\n",
    "              dtype='float64')\n",
    "rf.predict_proba(df2[['col1','col2','col3']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98f67d-b47e-43de-a41e-0e927bff6e43",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Expected output\n",
    "From documentation:\n",
    "```\n",
    "array([[0.8 , 0.2 ],\n",
    "       [0.38, 0.62],\n",
    "       [0.61, 0.39],\n",
    "       [0.65, 0.35],\n",
    "       [0.56, 0.44],\n",
    "       [0.63, 0.37],\n",
    "       [0.55, 0.45],\n",
    "       [0.43, 0.57],\n",
    "       [0.43, 0.57],\n",
    "       [0.38, 0.62]])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4994f47d-37e8-4992-9c38-762a713818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import csv\n",
    "\n",
    "# save the csv with the header, no index\n",
    "df2.to_csv('df2.csv', index=False)\n",
    "\n",
    "data_directory = BUCKET + \"/data\"\n",
    "storage_path = os.path.join(data_directory, 'df2.csv')\n",
    "blob = storage.blob.Blob.from_string(storage_path, client=storage.Client())\n",
    "blob.upload_from_filename(\"df2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "22a10c6c-18c1-4bf8-9641-61e4e1fe4602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating BatchPredictionJob\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob created. Resource name: projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944\n",
      "INFO:google.cloud.aiplatform.jobs:To use this BatchPredictionJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:bpj = aiplatform.BatchPredictionJob('projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944')\n",
      "INFO:google.cloud.aiplatform.jobs:View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/8388483720826322944?project=633325234048\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "batch_prediction_job = model.batch_predict(\n",
    "        job_display_name='pandas batch predict job sklearn - VALUES JSON',\n",
    "        gcs_source=storage_path,\n",
    "        gcs_destination_prefix=BUCKET+\"/predictions\",\n",
    "        machine_type='n1-standard-2',\n",
    "        instances_format='csv', #This is key to parsing CSV input\n",
    "        # accelerator_count=accelerator_count,\n",
    "        # accelerator_type=accelerator_type, #if you want gpus\n",
    "        starting_replica_count=1,\n",
    "        max_replica_count=2,\n",
    "        sync=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903dc3b1-3458-447d-ab53-a25774d6c2d6",
   "metadata": {},
   "source": [
    "### When successful you should see this\n",
    "```\n",
    "{\"instance\": [16.0, 64.0, 61.0], \"prediction\": [0.63, 0.37]}\n",
    "{\"instance\": [83.0, 27.0, 87.0], \"prediction\": [0.35, 0.65]}\n",
    "{\"instance\": [96.0, 83.0, 57.0], \"prediction\": [0.68, 0.32]}\n",
    "{\"instance\": [11.0, 62.0, 17.0], \"prediction\": [0.89, 0.11]}\n",
    "{\"instance\": [61.0, 28.0, 1.0], \"prediction\": [0.36, 0.64]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e0cbc-7abc-423c-b179-5ce65f7a95ca",
   "metadata": {},
   "source": [
    "## Batch Prediction with BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3b11a-4536-4ad8-89eb-596f1cb00801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pandas_gbq --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f618374-344b-4b0c-84de-c044db48fd88",
   "metadata": {},
   "source": [
    "## Create an empty dataset to house the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3134e415-e681-40cc-b002-b7b2b8f047dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'wortz-project:TEST' successfully created.\n"
     ]
    }
   ],
   "source": [
    "!bq --location=location mk \\\n",
    "--dataset \\\n",
    "--description \"test dataset\" \\\n",
    "--location \"US\" \\\n",
    "$PROJECT_ID:TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e94a22-cc73-486b-9a80-de49e9b5b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the table to BQ and make Batch predictions\n",
    "from pandas_gbq import to_gbq\n",
    "\n",
    "df2.to_gbq(destination_table=f\"{PROJECT_ID}.TEST.df2\", project_id=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c86c3-013b-4679-b75e-c26b76e4d743",
   "metadata": {},
   "source": [
    "## Bigquery magic comes available by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b4acea4a-b0ec-42fa-9eaa-04d80d5d14c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 865.70query/s] \n",
      "Downloading: 100%|██████████| 10/10 [00:01<00:00,  7.21rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>98.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>79.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2  col3\n",
       "0  20.0  12.0  62.0\n",
       "1  14.0  18.0  79.0\n",
       "2  56.0  19.0  81.0\n",
       "3  58.0  91.0  74.0\n",
       "4  77.0  49.0  99.0\n",
       "5  50.0  26.0  38.0\n",
       "6  49.0  23.0  69.0\n",
       "7  78.0  23.0  96.0\n",
       "8  98.0  36.0  15.0\n",
       "9  79.0  82.0  33.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select * from TEST.df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c4a7df-a0bb-4e8a-b6f8-df1f8392b9ce",
   "metadata": {},
   "source": [
    "## Now run batch predicitons on this bq table\n",
    "\n",
    "Note you have to have write permissions on the dataset - you may see a error if you don't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbfc3edb-8a9f-4502-976f-eee7afc3cc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating BatchPredictionJob\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob created. Resource name: projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592\n",
      "INFO:google.cloud.aiplatform.jobs:To use this BatchPredictionJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:bpj = aiplatform.BatchPredictionJob('projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592')\n",
      "INFO:google.cloud.aiplatform.jobs:View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/8652859092701806592?project=633325234048\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "batch_prediction_job = model.batch_predict(\n",
    "        job_display_name='bigquery batch predict job sklearn',\n",
    "        bigquery_source=f\"bq://{PROJECT_ID}.TEST.df2\",\n",
    "        bigquery_destination_prefix=f'bq://{PROJECT_ID}', #this will create a seperate dataset with predictions\n",
    "        machine_type='n1-standard-2',\n",
    "        # accelerator_count=accelerator_count,\n",
    "        # accelerator_type=accelerator_type, #if you want gpus\n",
    "        starting_replica_count=1,\n",
    "        max_replica_count=2,\n",
    "        sync=False,\n",
    "    ) \n",
    "\n",
    "# Output table will look something like this:  wortz-project.prediction_pandas_test_2022_04_22T11_32_14_834Z.predictions_2022_04_22T11_32_14_834Z "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846c8fad-2bff-45e8-a16a-c47950d7dc47",
   "metadata": {},
   "source": [
    "### Final section - deploy to endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "89b02089-f208-404f-b89c-5242bad4a0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Endpoint\n",
      "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/633325234048/locations/us-central1/endpoints/7875643460085088256/operations/7350682251878727680\n",
      "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/633325234048/locations/us-central1/endpoints/7875643460085088256\n",
      "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
      "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/633325234048/locations/us-central1/endpoints/7875643460085088256')\n",
      "INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/633325234048/locations/us-central1/endpoints/7875643460085088256\n",
      "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/633325234048/locations/us-central1/endpoints/7875643460085088256/operations/4151437666585411584\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/633325234048/locations/us-central1/endpoints/7875643460085088256\n"
     ]
    }
   ],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a305fccf-52d4-4323-9c0e-b9ca8b210240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[0.65, 0.35], [0.65, 0.35]], deployed_model_id='6711621286084214784', explanations=None)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob run completed. Resource name: projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944\n"
     ]
    }
   ],
   "source": [
    "endpoint.predict(instances=[[6.7, 3.1, 4.7], [4.6, 3.1, 1.5]])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
