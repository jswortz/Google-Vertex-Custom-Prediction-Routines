{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a35ff7d-279e-410c-834a-b81cdfc4f3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install google-cloud-aiplatform --user --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201e92f9-980b-43e9-8c76-b2aa02260e96",
   "metadata": {},
   "source": [
    "# Sklearn with Pandas - Custom Prediction Routine to get `.predict_proba()`\n",
    "\n",
    "This is similar to [the other notebook](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_cpr.ipynb) except we will be using pandas and bigquery\n",
    "\n",
    "Topics covered\n",
    "* Training sklearn locally, deploying to endpoint\n",
    "* Saving data as CSV and doing batch predict from GCS\n",
    "* Loading data to BQ, using BQ magics\n",
    "* Running a batch prediction from BQ to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "219a70e7-e777-48ac-85b3-b1ba5c455074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating gs://jsw-model-artifacts/...\n"
     ]
    }
   ],
   "source": [
    "# !gsutil mb -l us-central1 gs://jsw-model-artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cbe8a06-ed15-40ac-bc2f-d387bb406301",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'wortz-project-352116' #SET THIS TO YOUR PROJECT ID\n",
    "BUCKET = \"gs://jsw-model-artifacts\" #BE SURE TO gsutil mb -l <REGION> <LOG_BUCKET> to create the bucket on GCP\n",
    "REGION = \"us-central1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb15f1f6-9bc5-4e82-9c4f-3f9c33882868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate synthetic data\n",
    "import pandas as pd\n",
    "import numpy as np #for the random integer example\n",
    "\n",
    "# set seed\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "x = np.random.randint(0.0,100.0,size=(10,3))\n",
    "y = np.random.binomial(1, .25, size=(10,1))\n",
    "df = pd.DataFrame(np.append(x, y, axis=1),\n",
    "              index=range(10,20),\n",
    "              columns=['col1','col2','col3','label'],\n",
    "              dtype='float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13825936-816a-4b3f-a624-7c7684fc7c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>47.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>53.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>30.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>92.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>73.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>76.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    col1  col2  col3  label\n",
       "10  47.0  83.0  38.0    0.0\n",
       "11  53.0  76.0  24.0    1.0\n",
       "12  15.0  49.0  23.0    0.0\n",
       "13  26.0  30.0  43.0    0.0\n",
       "14  30.0  26.0  58.0    1.0\n",
       "15  92.0  69.0  80.0    0.0\n",
       "16  73.0  47.0  50.0    0.0\n",
       "17  76.0  37.0  34.0    1.0\n",
       "18  38.0  67.0  11.0    0.0\n",
       "19   0.0  75.0  80.0    1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b0849f09-5f48-4e73-96db-c2fa53c06ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=6, max_features=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=6, max_features=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(max_depth=6, max_features=3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Set the model parameters. \n",
    "n_estimators = 100\n",
    "max_depth = 6\n",
    "max_features = 3\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators = n_estimators, max_depth = max_depth, max_features = max_features)\n",
    "rf.fit(df[['col1', 'col2', 'col3']], df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9d32fb67-b6f8-40fc-b335-95c41c2c3133",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "artifact_filename = 'model.joblib' #has to be joblib to work with CPR\n",
    "\n",
    "# Save model artifact to local filesystem (doesn't persist)\n",
    "\n",
    "joblib.dump(rf, artifact_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07022a43-5b9b-45bc-84af-f43173e627a4",
   "metadata": {},
   "source": [
    "#### Upload the model pipeline to gcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41e83b92-13d2-4881-b27f-091e96af4262",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://model.joblib [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 83.9 KiB/ 83.9 KiB]                                                \n",
      "Operation completed over 1 objects/83.9 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "! gsutil cp $artifact_filename $BUCKET/model/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c749d4-18ca-46a0-91f9-432dbf1220e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create a generic sklearn container that returns `predict_proba`\n",
    "\n",
    "https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/ml_ops/stage6/get_started_with_cpr.ipynb\n",
    "\n",
    "**highly recommend reviewing this notebook first as it breaks down the custom predictor interface**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bf429ed-e23c-47ac-93da-8a70c4e3e92a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘src’: File exists\n"
     ]
    }
   ],
   "source": [
    "! mkdir src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4af962a7-3196-4b9a-9c36-3f35fd525b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/requirements.txt\n",
    "fastapi\n",
    "uvicorn\n",
    "scikit-learn\n",
    "google-cloud-storage\n",
    "google-cloud-aiplatform[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d808c149-acef-4d7f-873a-62f372f3393e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/predictor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/predictor.py\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from google.cloud import storage\n",
    "from google.cloud.aiplatform.prediction.predictor import Predictor\n",
    "from google.cloud.aiplatform.utils import prediction_utils\n",
    "\n",
    "import json\n",
    "\n",
    "class CprPredictor(Predictor):\n",
    "    \n",
    "    def __init__(self):\n",
    "        return\n",
    "    \n",
    "    def load(self, gcs_artifacts_uri: str):\n",
    "        \"\"\"Loads the preprocessor artifacts.\"\"\"\n",
    "        prediction_utils.download_model_artifacts(gcs_artifacts_uri)\n",
    "        # gcs_client = storage.Client()\n",
    "        # with open(\"model.joblib\", 'wb') as gcs_model:\n",
    "        #     gcs_client.download_blob_to_file(\n",
    "        #         gcs_artifacts_uri + \"/model.joblib\", gcs_model\n",
    "        #     )\n",
    "\n",
    "        with open(\"model.joblib\", \"rb\") as f:\n",
    "            self._model = joblib.load(\"model.joblib\")\n",
    "\n",
    "    \n",
    "    def predict(self, instances):\n",
    "        outputs = self._model.predict_proba(instances) \n",
    "        outputs = [list(output) for output in outputs] #convert array to list\n",
    "        return {'predictions': outputs}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13e2ff0-bc14-4b89-a193-78f9f12b6261",
   "metadata": {},
   "source": [
    "#### Build a custom handler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "448f7eaa-60ee-4690-8624-f01f3a74af15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/handler.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/handler.py\n",
    "\n",
    "import csv\n",
    "from io import StringIO\n",
    "import json\n",
    "\n",
    "from fastapi import Response\n",
    "\n",
    "from google.cloud.aiplatform.prediction.handler import PredictionHandler\n",
    "\n",
    "class CprHandler(PredictionHandler):\n",
    "    \"\"\"Default prediction handler for the prediction requests sent to the application.\"\"\"\n",
    "\n",
    "    async def handle(self, request):\n",
    "        \"\"\"Handles a prediction request.\"\"\"\n",
    "        request_body = await request.body()\n",
    "        request_body_dict = json.loads(request_body)\n",
    "        instances=request_body_dict[\"instances\"]\n",
    "        prediction_results = self._predictor.predict(instances)\n",
    "\n",
    "        return Response(content=json.dumps(prediction_results))\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a17737-58ad-4819-9b2d-72de6fd6e827",
   "metadata": {},
   "source": [
    "### Build and push container to Artifact Registry\n",
    "#### Build your container\n",
    "To build a custom container, we also need to write an entrypoint of the image that starts the model server. However, with the Custom Prediction Routine feature, you don't need to write the entrypoint anymore. Vertex AI SDK will populate the entrypoint with the custom predictor you provide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6178e71d-2dfa-4095-b623-35ffbe2a7650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow/lib/python3.10/subprocess.py:955: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
      "/opt/conda/envs/tensorflow/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
     ]
    }
   ],
   "source": [
    "from google.cloud.aiplatform.prediction import LocalModel\n",
    "from src.predictor import CprPredictor\n",
    "from src.handler import CprHandler\n",
    "# {import your predictor and handler}\n",
    "REPOSITORY = \"sklearn-preprocess\"  # @param {type:\"string\"}\n",
    "SERVER_IMAGE = \"sklearn-cpr-preprocess\"  # @param {type:\"string\"}\n",
    "USER_SRC_DIR = 'src'\n",
    "\n",
    "local_model = LocalModel.build_cpr_model(\n",
    "    USER_SRC_DIR,\n",
    "    f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{REPOSITORY}/{SERVER_IMAGE}\",\n",
    "    predictor=CprPredictor,\n",
    "    handler=CprHandler,\n",
    "    requirements_path=os.path.join(USER_SRC_DIR, \"requirements.txt\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80330616-933a-4ec9-9322-2dd5815c4947",
   "metadata": {},
   "source": [
    "### Test it out with a locally deployed endpoint\n",
    "Need to generate credentials to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a01981a9-6972-4eb9-b7ba-18689a31b90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_uri: \"us-central1-docker.pkg.dev/wortz-project/sklearn-preprocess/sklearn-cpr-preprocess\"\n",
       "predict_route: \"/predict\"\n",
       "health_route: \"/health\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_model.get_serving_container_spec()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1499c3a-71d5-4b1c-8ab5-09cb11a212be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! gcloud services enable iam.googleapis.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efa05b7-4303-4655-9cc0-069be8bcf969",
   "metadata": {},
   "source": [
    "#### Only run once to generate creds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "741aa916-d6e6-47eb-8463-867cba4eca94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! gcloud iam service-accounts keys create credentials.json --iam-account=633325234048-compute@developer.gserviceaccount.com\n",
    "CREDENTIALS_FILE = \"/home/jupyter/.config/gcloud/application_default_credentials.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f057e698-b11f-4aa3-9aa5-4e23021dcc1b",
   "metadata": {},
   "source": [
    "## Create example instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "65d19e00-fd9a-4166-a6ec-324a8d37208a",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_FILE = \"instances.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2deece3e-c7f0-4513-be68-114746a5ebbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting instances.json\n"
     ]
    }
   ],
   "source": [
    "%%writefile $INPUT_FILE\n",
    "{\n",
    "    \"instances\": [\n",
    "        [61.7, 11.1, 41.7],\n",
    "        [41.6, 31.1, 11.5]\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4b7bcac6-86de-4afe-a70f-ff7eadfe2865",
   "metadata": {},
   "outputs": [],
   "source": [
    "with local_model.deploy_to_local_endpoint(\n",
    "    artifact_uri=f\".\",\n",
    "    credential_path=CREDENTIALS_FILE,  # Update this to the path to your credentials.\n",
    ") as local_endpoint:\n",
    "    predict_response = local_endpoint.predict(\n",
    "        request_file=INPUT_FILE,\n",
    "        headers={\"Content-Type\": \"application/json\"},\n",
    "    )\n",
    "    \n",
    "    health_check_response = local_endpoint.run_health_check()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97275bb5-4268-4222-b059-c195c6144d27",
   "metadata": {},
   "source": [
    "## Local results should show a n x 2 shaped return for binomial classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eb292702-f06f-454a-a90f-e259f7578f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'{\"predictions\": [[0.37, 0.63], [0.67, 0.33]]}'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963400a8-e35a-49eb-854f-46a5421901a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create a repository to house your artifacts / images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dc4cafdd-446b-4b1a-9d02-de386b3cc156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !gcloud services enable artifactregistry.googleapis.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eea578e6-7b7c-4317-927a-d80741553859",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mERROR:\u001b[0m (gcloud.artifacts.repositories.create) ALREADY_EXISTS: the repository already exists\n"
     ]
    }
   ],
   "source": [
    "! gcloud artifacts repositories create {REPOSITORY} \\\n",
    "    --repository-format=docker \\\n",
    "    --location=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "51a36035-b4ad-4ffa-97cd-444ebbbaf03e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;33mWARNING:\u001b[0m Your config file at [/home/jupyter/.docker/config.json] contains these credential helper entries:\n",
      "\n",
      "{\n",
      "  \"credHelpers\": {\n",
      "    \"gcr.io\": \"gcloud\",\n",
      "    \"us.gcr.io\": \"gcloud\",\n",
      "    \"eu.gcr.io\": \"gcloud\",\n",
      "    \"asia.gcr.io\": \"gcloud\",\n",
      "    \"staging-k8s.gcr.io\": \"gcloud\",\n",
      "    \"marketplace.gcr.io\": \"gcloud\",\n",
      "    \"us-central1-docker.pkg.dev\": \"gcloud\"\n",
      "  }\n",
      "}\n",
      "Adding credentials for: us-central1-docker.pkg.dev\n",
      "gcloud credential helpers already registered correctly.\n"
     ]
    }
   ],
   "source": [
    "! gcloud auth configure-docker {REGION}-docker.pkg.dev --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a979a4-48a8-4453-90a3-3629957bd878",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Upload the model to Vertex using new Prediction Route Serving Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "59eb3650-759a-40a1-bd2f-704daad82410",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/tensorflow/lib/python3.10/subprocess.py:955: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdin = io.open(p2cwrite, 'wb', bufsize)\n",
      "/opt/conda/envs/tensorflow/lib/python3.10/subprocess.py:961: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "  self.stdout = io.open(c2pread, 'rb', bufsize)\n"
     ]
    }
   ],
   "source": [
    "local_model.push_image() #push to container registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80d8e71d-9702-4c7d-bd15-925278f759d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Model\n",
      "Create Model backing LRO: projects/679926387543/locations/us-central1/models/8285204944361881600/operations/6779270319531098112\n",
      "Model created. Resource name: projects/679926387543/locations/us-central1/models/8285204944361881600@1\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/679926387543/locations/us-central1/models/8285204944361881600@1')\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import aiplatform\n",
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "MODEL_DISPLAY_NAME = 'pandas test CLASSIFICATION'\n",
    "\n",
    "model = aiplatform.Model.upload(\n",
    "    local_model=local_model,\n",
    "    display_name=MODEL_DISPLAY_NAME,\n",
    "    artifact_uri=f\"{BUCKET}/model\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b7e030-a234-40ad-8c8d-bc0ece95d93f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Batch predictions with GCS / CSV\n",
    "### Now we will create a different dataframe to make predictions on for batch predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f8328221-1c7c-4c65-bf71-59b59b75a7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.77, 0.23],\n",
       "       [0.38, 0.62],\n",
       "       [0.72, 0.28],\n",
       "       [0.76, 0.24],\n",
       "       [0.7 , 0.3 ],\n",
       "       [0.23, 0.77],\n",
       "       [0.77, 0.23],\n",
       "       [0.76, 0.24],\n",
       "       [0.38, 0.62],\n",
       "       [0.77, 0.23]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame(np.random.randint(0.0,100.0,size=(10,3)), # we will do batch predictions based on this\n",
    "              index=range(10,20),\n",
    "              columns=['col1','col2','col3'],\n",
    "              dtype='float64')\n",
    "rf.predict_proba(df2[['col1','col2','col3']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98f67d-b47e-43de-a41e-0e927bff6e43",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Expected output\n",
    "From documentation:\n",
    "```\n",
    "array([[0.8 , 0.2 ],\n",
    "       [0.38, 0.62],\n",
    "       [0.61, 0.39],\n",
    "       [0.65, 0.35],\n",
    "       [0.56, 0.44],\n",
    "       [0.63, 0.37],\n",
    "       [0.55, 0.45],\n",
    "       [0.43, 0.57],\n",
    "       [0.43, 0.57],\n",
    "       [0.38, 0.62]])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8ae78f-397a-43be-9d8f-e0d5f016c6e5",
   "metadata": {},
   "source": [
    "#### Regular predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "67313475-269c-4e81-afdd-07905b59ef73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Endpoint\n",
      "Create Endpoint backing LRO: projects/679926387543/locations/us-central1/endpoints/8664558446177157120/operations/6869342312078508032\n",
      "Endpoint created. Resource name: projects/679926387543/locations/us-central1/endpoints/8664558446177157120\n",
      "To use this Endpoint in another session:\n",
      "endpoint = aiplatform.Endpoint('projects/679926387543/locations/us-central1/endpoints/8664558446177157120')\n",
      "Deploying model to Endpoint : projects/679926387543/locations/us-central1/endpoints/8664558446177157120\n",
      "Deploy Endpoint model backing LRO: projects/679926387543/locations/us-central1/endpoints/8664558446177157120/operations/6382953552322494464\n",
      "BatchPredictionJob projects/679926387543/locations/us-central1/batchPredictionJobs/5729541692042772480 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "BatchPredictionJob projects/679926387543/locations/us-central1/batchPredictionJobs/5729541692042772480 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "Endpoint model deployed. Resource name: projects/679926387543/locations/us-central1/endpoints/8664558446177157120\n"
     ]
    }
   ],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6cab1eb5-04c2-41ec-af2e-39dd7d67e25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13., 56., 48.],\n",
       "       [58., 94., 35.],\n",
       "       [57., 60., 83.],\n",
       "       [ 9., 60., 50.],\n",
       "       [51., 49., 71.],\n",
       "       [81.,  4.,  3.],\n",
       "       [88., 46., 94.],\n",
       "       [47., 63., 84.],\n",
       "       [ 5., 83., 72.],\n",
       "       [72., 63., 56.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "dbead943-03f0-4612-b8cc-c3f83b59842b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[0.79, 0.21], [0.49, 0.51], [0.62, 0.38], [0.79, 0.21], [0.61, 0.39], [0.31, 0.69], [0.73, 0.27], [0.62, 0.38], [0.46, 0.54], [0.67, 0.33]], deployed_model_id='3675493648817979392', model_version_id='1', model_resource_name='projects/679926387543/locations/us-central1/models/8285204944361881600', explanations=None)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint.predict(df2.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2501aef9-6cb6-435f-9857-382e160b93f5",
   "metadata": {},
   "source": [
    "#### Batch predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4994f47d-37e8-4992-9c38-762a713818b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import csv\n",
    "\n",
    "# save the csv with the header, no index\n",
    "df2.to_csv('df2.csv', index=False)\n",
    "\n",
    "data_directory = BUCKET + \"/data\"\n",
    "storage_path = os.path.join(data_directory, 'df2.csv')\n",
    "blob = storage.blob.Blob.from_string(storage_path, client=storage.Client())\n",
    "blob.upload_from_filename(\"df2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "22a10c6c-18c1-4bf8-9641-61e4e1fe4602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating BatchPredictionJob\n",
      "BatchPredictionJob created. Resource name: projects/679926387543/locations/us-central1/batchPredictionJobs/5729541692042772480\n",
      "To use this BatchPredictionJob in another session:\n",
      "bpj = aiplatform.BatchPredictionJob('projects/679926387543/locations/us-central1/batchPredictionJobs/5729541692042772480')\n",
      "View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/5729541692042772480?project=679926387543\n",
      "BatchPredictionJob projects/679926387543/locations/us-central1/batchPredictionJobs/5729541692042772480 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "BatchPredictionJob projects/679926387543/locations/us-central1/batchPredictionJobs/5729541692042772480 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "BatchPredictionJob projects/679926387543/locations/us-central1/batchPredictionJobs/5729541692042772480 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "batch_prediction_job = model.batch_predict(\n",
    "        job_display_name='pandas batch predict job sklearn - VALUES JSON',\n",
    "        gcs_source=storage_path,\n",
    "        gcs_destination_prefix=BUCKET+\"/predictions\",\n",
    "        machine_type='n1-standard-2',\n",
    "        instances_format='csv', #This is key to parsing CSV input\n",
    "        # accelerator_count=accelerator_count,\n",
    "        # accelerator_type=accelerator_type, #if you want gpus\n",
    "        starting_replica_count=1,\n",
    "        max_replica_count=2,\n",
    "        sync=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903dc3b1-3458-447d-ab53-a25774d6c2d6",
   "metadata": {},
   "source": [
    "### When successful you should see this\n",
    "```\n",
    "{\"instance\": [16.0, 64.0, 61.0], \"prediction\": [0.63, 0.37]}\n",
    "{\"instance\": [83.0, 27.0, 87.0], \"prediction\": [0.35, 0.65]}\n",
    "{\"instance\": [96.0, 83.0, 57.0], \"prediction\": [0.68, 0.32]}\n",
    "{\"instance\": [11.0, 62.0, 17.0], \"prediction\": [0.89, 0.11]}\n",
    "{\"instance\": [61.0, 28.0, 1.0], \"prediction\": [0.36, 0.64]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71e0cbc-7abc-423c-b179-5ce65f7a95ca",
   "metadata": {},
   "source": [
    "## Batch Prediction with BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e3b11a-4536-4ad8-89eb-596f1cb00801",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pandas_gbq --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f618374-344b-4b0c-84de-c044db48fd88",
   "metadata": {},
   "source": [
    "## Create an empty dataset to house the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3134e415-e681-40cc-b002-b7b2b8f047dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'wortz-project:TEST' successfully created.\n"
     ]
    }
   ],
   "source": [
    "!bq --location=location mk \\\n",
    "--dataset \\\n",
    "--description \"test dataset\" \\\n",
    "--location \"US\" \\\n",
    "$PROJECT_ID:TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e94a22-cc73-486b-9a80-de49e9b5b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the table to BQ and make Batch predictions\n",
    "from pandas_gbq import to_gbq\n",
    "\n",
    "df2.to_gbq(destination_table=f\"{PROJECT_ID}.TEST.df2\", project_id=PROJECT_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1c86c3-013b-4679-b75e-c26b76e4d743",
   "metadata": {},
   "source": [
    "## Bigquery magic comes available by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b4acea4a-b0ec-42fa-9eaa-04d80d5d14c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query complete after 0.00s: 100%|██████████| 1/1 [00:00<00:00, 865.70query/s] \n",
      "Downloading: 100%|██████████| 10/10 [00:01<00:00,  7.21rows/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>77.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>99.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>49.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>78.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>96.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>98.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>79.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2  col3\n",
       "0  20.0  12.0  62.0\n",
       "1  14.0  18.0  79.0\n",
       "2  56.0  19.0  81.0\n",
       "3  58.0  91.0  74.0\n",
       "4  77.0  49.0  99.0\n",
       "5  50.0  26.0  38.0\n",
       "6  49.0  23.0  69.0\n",
       "7  78.0  23.0  96.0\n",
       "8  98.0  36.0  15.0\n",
       "9  79.0  82.0  33.0"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%bigquery\n",
    "select * from TEST.df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c4a7df-a0bb-4e8a-b6f8-df1f8392b9ce",
   "metadata": {},
   "source": [
    "## Now run batch predicitons on this bq table\n",
    "\n",
    "Note you have to have write permissions on the dataset - you may see a error if you don't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbfc3edb-8a9f-4502-976f-eee7afc3cc13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating BatchPredictionJob\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob created. Resource name: projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592\n",
      "INFO:google.cloud.aiplatform.jobs:To use this BatchPredictionJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:bpj = aiplatform.BatchPredictionJob('projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592')\n",
      "INFO:google.cloud.aiplatform.jobs:View Batch Prediction Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/batch-predictions/8652859092701806592?project=633325234048\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8652859092701806592 current state:\n",
      "JobState.JOB_STATE_RUNNING\n"
     ]
    }
   ],
   "source": [
    "batch_prediction_job = model.batch_predict(\n",
    "        job_display_name='bigquery batch predict job sklearn',\n",
    "        bigquery_source=f\"bq://{PROJECT_ID}.TEST.df2\",\n",
    "        bigquery_destination_prefix=f'bq://{PROJECT_ID}', #this will create a seperate dataset with predictions\n",
    "        machine_type='n1-standard-2',\n",
    "        # accelerator_count=accelerator_count,\n",
    "        # accelerator_type=accelerator_type, #if you want gpus\n",
    "        starting_replica_count=1,\n",
    "        max_replica_count=2,\n",
    "        sync=False,\n",
    "    ) \n",
    "\n",
    "# Output table will look something like this:  wortz-project.prediction_pandas_test_2022_04_22T11_32_14_834Z.predictions_2022_04_22T11_32_14_834Z "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846c8fad-2bff-45e8-a16a-c47950d7dc47",
   "metadata": {},
   "source": [
    "### Final section - deploy to endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "89b02089-f208-404f-b89c-5242bad4a0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.models:Creating Endpoint\n",
      "INFO:google.cloud.aiplatform.models:Create Endpoint backing LRO: projects/633325234048/locations/us-central1/endpoints/7875643460085088256/operations/7350682251878727680\n",
      "INFO:google.cloud.aiplatform.models:Endpoint created. Resource name: projects/633325234048/locations/us-central1/endpoints/7875643460085088256\n",
      "INFO:google.cloud.aiplatform.models:To use this Endpoint in another session:\n",
      "INFO:google.cloud.aiplatform.models:endpoint = aiplatform.Endpoint('projects/633325234048/locations/us-central1/endpoints/7875643460085088256')\n",
      "INFO:google.cloud.aiplatform.models:Deploying model to Endpoint : projects/633325234048/locations/us-central1/endpoints/7875643460085088256\n",
      "INFO:google.cloud.aiplatform.models:Deploy Endpoint model backing LRO: projects/633325234048/locations/us-central1/endpoints/7875643460085088256/operations/4151437666585411584\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.models:Endpoint model deployed. Resource name: projects/633325234048/locations/us-central1/endpoints/7875643460085088256\n"
     ]
    }
   ],
   "source": [
    "endpoint = model.deploy(machine_type=\"n1-standard-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a305fccf-52d4-4323-9c0e-b9ca8b210240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(predictions=[[0.65, 0.35], [0.65, 0.35]], deployed_model_id='6711621286084214784', explanations=None)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "INFO:google.cloud.aiplatform.jobs:BatchPredictionJob run completed. Resource name: projects/633325234048/locations/us-central1/batchPredictionJobs/8388483720826322944\n"
     ]
    }
   ],
   "source": [
    "endpoint.predict(instances=[[6.7, 3.1, 4.7], [4.6, 3.1, 1.5]])"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-tensorflow-tensorflow",
   "name": "workbench-notebooks.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m110"
  },
  "kernelspec": {
   "display_name": "TensorFlow 2-11",
   "language": "python",
   "name": "conda-env-tensorflow-tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
